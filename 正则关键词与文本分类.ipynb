{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ea07b02-6684-4085-b189-dc38bc071cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\hjg\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.253 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "C:\\Users\\hjg\\AppData\\Local\\Temp\\ipykernel_15016\\3380694067.py:64: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  train_word_prior.groupby('category').apply(lambda x:list(x.index))\n",
      "C:\\Users\\hjg\\AppData\\Local\\Temp\\ipykernel_15016\\3380694067.py:66: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df=train_word_prior.groupby('category').apply(lambda x:list(x.index))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#读取数据集\n",
    "train_data=pd.read_csv('C:\\\\Users\\\\hjg\\\\OneDrive\\\\桌面\\\\对话意图识别\\\\train.csv',sep='\\t',header=None)\n",
    "test_data=pd.read_csv('C:\\\\Users\\\\hjg\\\\OneDrive\\\\桌面\\\\对话意图识别\\\\test.csv',sep='\\t',header=None)\n",
    "#分词\n",
    "train_text=' '.join(list(train_data[0]))\n",
    "train_words=jieba.cut(train_text)\n",
    "#读取停用词\n",
    "cn_stopwords = ' '.join(str(x) for x in pd.read_csv('https://mirror.coggle.club/stopwords/baidu_stopwords.txt', header=None)[0])\n",
    "train_words=[x for x in train_words if x not in cn_stopwords]\n",
    "train_words=[x for x in train_words if len(x)>1]\n",
    "train_words=[x for x in train_words if not x.isdigit()]#剔除纯数字                    \n",
    "\n",
    "# 统计每个单词出现的频次\n",
    "from collections import Counter\n",
    "train_words_freq=Counter(train_words)\n",
    "# 过滤频次比较低的单词\n",
    "train_words=[x for x in train_words if train_words_freq[x]>=5]\n",
    "\n",
    "#定义一个字典\n",
    "train_word_prior={}\n",
    "#对于训练集的每个样本\n",
    "for row in train_data.iloc[:].itertuples():\n",
    "    # text与label分别对应这行的文本数据与标签数据\n",
    "    text,label=row[1],row[2]\n",
    "    \n",
    "    #将每行的第一列文本数据分词\n",
    "    words=jieba.cut(text)\n",
    "    \n",
    "    #保证每行的词出现在已经筛好的词汇表中\n",
    "    words=[x for x in words if x in train_words]\n",
    "    \n",
    "    #如果words为0，代表这行数据是脏数据，不统计\n",
    "    if len(words)==0:\n",
    "        continue\n",
    "    #对每个单词进行统计（计算）\n",
    "    for word in words:\n",
    "        #如果字典中未出现这个单词，定义total为0\n",
    "        if word not in train_word_prior:\n",
    "            train_word_prior[word]={\"total\":0}\n",
    "        #如果字典中的单词未出现这个单词对应的标签，则打上标记，赋值为0\n",
    "        if label not in train_word_prior[word]:\n",
    "            train_word_prior[word][label]=0\n",
    "    #计数\n",
    "    train_word_prior[word][label]+=1\n",
    "    train_word_prior[word]['total']+=1\n",
    "\n",
    "\n",
    "# 转换成DataFrame表格形式并转置\n",
    "train_word_prior=pd.DataFrame(train_word_prior).T\n",
    "# 填充缺失值，处理单词在其他意图中没有出现的情况\n",
    "train_word_prior.fillna(0,inplace=True)\n",
    "\n",
    "\n",
    "#计算单词在每个类别出现的概率,得到每个单词所对应的意图\n",
    "for category in train_data[1].unique():\n",
    "    train_word_prior[category]/=train_word_prior['total']\n",
    "\n",
    "# 每个意图所对应的单词\n",
    "train_word_prior['category']=train_word_prior.columns[1:][train_word_prior.values[:,1:].argmax(1)]\n",
    "train_word_prior.groupby('category').apply(lambda x:list(x.index))\n",
    "\n",
    "df=train_word_prior.groupby('category').apply(lambda x:list(x.index))\n",
    "intent_categories=df.index\n",
    "\n",
    "#意图类别所对应的规则\n",
    "import re\n",
    "intent_patterns=[re.compile('|'.join(x)) for x in df.values]\n",
    "\n",
    "test_pred=[]\n",
    "for test in test_data[0]: \n",
    "    single_pred=''\n",
    "    for category,pattern in zip(intent_categories,intent_patterns):\n",
    "        if re.findall(pattern,test):\n",
    "            single_pred=category\n",
    "            break\n",
    "    if single_pred=='':\n",
    "        single_pred='Other'\n",
    "    test_pred.append(single_pred)\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"ID\": range(1,len(test_data)+1),\n",
    "        \"Target\": test_pred\n",
    "    }\n",
    ").to_csv('正则提交.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162c3105-bde1-41e9-be8c-c8327ef7badc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
